---
title: "Attenberg2013 Reproduction"
author: "Harel Lustiger"
#date: "22 October, 2015"
#abstract: "This is a reproduction of chapter 3 in [@Attenberg2013]"
output: 
#  pdf_document: 
#    highlight: tango
  html_document: 
    highlight: tango
    theme: journal
bibliography: references.bib   
nocite: | 
        @Attenberg2013
---

```{r global_options, include=FALSE, echo=FALSE}
Sys.setlocale("LC_TIME", "English")

packages_list = c("knitr","pander")
sapply(packages_list, 
       function(package){
           if(!require(package, character.only=TRUE)) 
               install.packages(package,dep=TRUE)
           require(package, character.only=TRUE)})

opts_chunk$set(fig.width=8, fig.height=4, fig.path='figs/', dev='png', dpi=300, 
               echo=FALSE, warning=FALSE, message=FALSE, results='hide')
```

```{r pandoc_options, include=FALSE, echo=FALSE}
panderOptions('table.split.table', Inf)
panderOptions('digits', 3)
panderOptions('round', 3)
panderOptions('keep.trailing.zeros', TRUE)
# performance.table <- table(some_table)
# pandoc.table(performance.table, style = "rmarkdown", justify = 'left', 
# caption = 'Performance table') 
```

`r format(Sys.time(), "%d-%b-%Y")`

# Performance Metrics

* **g-means**, $g = \sqrt{\text{sensitivity}\cdot \text{specificity}}$
* **AUC**, area under the ROC curve
* **PRBEF**, Precision Recall Break-Even Point

# Datasets [@ertekin2007learning]

We used 4 benchmark datasets from the popular UCI Machine Learning Repository.

* _Letter_ and _Satimage_ are image datasets.
    * The 'letter A' is used as the positive class in _Letter_. 
    * 'class 4' (damp grey soil) is used as positive class in _Satimage_. 
* _Abalone_ is a biology dataset. 
    * instances labeled as 'class 7' are used to form the positive class.    
* _Adult_ is a Census database where instances labeled as '>50K' are 24% of 
  the dataset.

<!--- The overview of the datasets are given in the following table. -->



```{r dataset_table, results='asis'}
#table = 

```

# Experiments and Empirical Evaluation

## Data efficiency

In the experiments, an early stopping heuristic for active learning is employed,
since it has been shown that active learning converges to the solution faster 
than the random sample selection method [@ertekin2007learning].

<!---
Figure 4: Comparison of PRBEP of AL and RS on the adult datasets with different
imbalance ratios (Imb.R.=3, 10, 20, 30).
-->

<!---
Table 1: Comparison of g-means and AUC for AL and RS with entire training data
(Batch). SV ratios are given at the saturation point. Data efficiency 
corresponds to the percentage of training instances which AL processes to reach
saturation.
-->

# References