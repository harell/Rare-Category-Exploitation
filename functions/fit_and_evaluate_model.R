#' Fit and Evaluate model
#'
#' @param train_set
#' @param test_set
#' @param inducer; if input argument is a svm object then the function use it 
#'                 to evaluate the datasets. Else first fit the model and then 
#'                 evaluate.
#' @param verbose
#' 
#' @return criteria list
#' 
fit_and_evaluate_model = function(train_set,
                                  test_set,
                                  inducer=c("SVM","GLM"),
                                  seed=1984,
                                  verbose=TRUE){
    return_list = list()
    options(warn=-1)
    ###############################
    # Standardize variables names #
    ###############################
    colnames(train_set) = c(paste0("X",1:(ncol(train_set)-1)),"label")  
    colnames(test_set)  = c(paste0("X",1:(ncol(test_set)-1)),"label")  
    n_te_minority = sum(test_set$label %in% "minority")
    n_te_majority = sum(test_set$label %in% "majority")
    n_tr_minority = sum(train_set$label %in% "minority")
    n_tr_majority = sum(train_set$label %in% "majority")
    # stopifnot(n_tr_minority>0, n_tr_majority>0)
    # stopifnot(n_te_minority>0, n_te_majority>0)
    
    
    #################################
    # Fit model to the training-set #
    #################################
    set.seed(seed)
    
    if(any(class(inducer) %in% c("svm","glm"))){
        model = inducer
        return_list[["Model"]] = model
        
    } else if(tolower(inducer) == "svm"){
        if(verbose) cat("\n# fitting and evaluating SVM model")
        model = e1071::svm(label ~ ., data=train_set,
                           kernel="radial", cost=1e0,
                           scale=T, probability=TRUE)
        return_list[["Model"]] = model
        
    } else if(tolower(inducer) == "glm"){
        if(verbose) cat("\n# fitting and evaluating GLM model")
        # Remove factor variables with no variance
        for(j in (ncol(train_set)-1):1)
        {
            if(class(train_set[,j]) == "factor")      ## Is that a factor variable?
                if((sum(table(train_set[,j])>0)) < 2) ## Does it have less than 2 unique values?
                    train_set = train_set[,-j]        ## Drop the variable
        }# end for removing nv variables
        if(verbose) 
            if(ncol(test_set) != ncol(train_set))
                cat("\t# Removed", ncol(test_set)-ncol(train_set), "factor variables with no variance")
        
        # Fit GLM to train sey
        model = glm(label ~ ., data=train_set,
                    family = "binomial")
        return_list[["Model"]] = model
        
    } else
        stop("Unknown inducer")
    
    
    #######################################
    # Extract elements of the SVM object  #
    #######################################
    # Support Vectors information
    if(tolower(inducer) == "glm" | any(class(inducer) %in% "glm"))
    {
        return_list[["SV_total"]]    = NA
        return_list[["SV_minority"]] = NA
        return_list[["SV_majority"]] = NA 
    } else if((tolower(inducer) == "svm" | any(class(inducer) %in% "svm"))) {
        SV_index = rownames(model$SV)
        return_list[["SV_total"]]    = length(SV_index)
        return_list[["SV_minority"]] = table(train_set[SV_index,"label"])[["minority"]]
        return_list[["SV_majority"]] = table(train_set[SV_index,"label"])[["majority"]] 
    } # end if glm or svm
    
    
    #########################################
    # Predict the training set and test set #
    #########################################
    # If test-set is empty then don't proceed to observations estimation phase
    if(nrow(test_set)<=0) return(return_list) # no test-set was supplied
    
    if(tolower(inducer) == "svm" | any(class(inducer) == "svm")){
        
        est_te = predict(model, test_set, probability=TRUE)
        est_te = attr(est_te, "probabilities") 
        predictions_te = unlist(est_te[,"minority"])
        ind_te = as.numeric(names(est_te[,"minority"]))
        
        est_tr = predict(model, train_set, probability=TRUE)
        est_tr = attr(est_tr, "probabilities")
        predictions_tr = unlist(est_tr[,"minority"])
        ind_tr = as.numeric(names(est_tr[,"minority"]))
        
    } else if(tolower(inducer) == "glm" | any(class(inducer) == "glm")){
        
        # GLM doesn't know how to handle factor levels which are not represented 
        # in the train set, therefore a correction is needed
        test_set_mod  = test_set
        train_set_mod = train_set
        for(i in 1:ncol(model$data)){
            if(is.factor(model$data[,i])){
                # Test-set
                id <- which(!(test_set[,i] %in% unique(model$data[,i])))
                test_set_mod[id,i] <- NA
                # Train-set
                id <- which(!(train_set[,i] %in% unique(model$data[,i])))
                train_set_mod[id,i] <- NA
            }# end if
        }# end for
        
        est_te = predict(model, test_set_mod, type="response")
        ind_te = as.numeric(names(est_te))
        predictions_te = unlist(est_te)
        
        est_tr = predict(model, train_set_mod, type="response")
        ind_tr = as.numeric(names(est_tr))
        predictions_tr = unlist(est_tr)
        
    }# end prediction
    
    # Replace NA's within the prediction vector with 0 probabilities
    # In case we replace the unseen factor levels with NAs, the corresponding 
    # estimated probabilities are also NA's
    if(any(is.na(predictions_te))) warning("fit_and_evaluate_model detected NAs predictions in test-set and replced then with 0")
    if(any(is.na(predictions_tr))) warning("fit_and_evaluate_model detected NAs predictions in train-set and replced then with 0")
    predictions_te[is.na(predictions_te)] = 0
    predictions_tr[is.na(predictions_tr)] = 0
    
    
    # Store prediction
    test_set_predictions = data.frame("Index"=ind_te,
                                      "Minority_Probability"=predictions_te,
                                      "Ground_Truth"=test_set$label)
    rownames(test_set_predictions) = NULL
    
    train_set_predictions = data.frame("Index"=ind_tr,
                                       "Minority_Probability"=predictions_tr,
                                       "Ground_Truth"=train_set$label)
    rownames(train_set_predictions) = NULL
    
    
    ############################
    # Output model estimations #
    ############################
    return_list[["Test_set_predictions"]]  = test_set_predictions[order(test_set_predictions$Index),]
    return_list[["Train_set_predictions"]] = train_set_predictions[order(train_set_predictions$Index),]
    # If test-set has no minority-class or no majority-class then don't proceed 
    # to model evaluation phase 
    if(n_te_minority<1 | n_te_majority<1) return(return_list) 
    
    
    ##################################
    # Evaluate model on the test-set #
    ##################################
    pred  = ROCR::prediction(predictions_te, test_set[,"label"])
    ## Precision and Recall
    PR_obj        = ROCR::performance(pred, "prec", "rec")
    Recall_vec    = unlist(PR_obj@x.values)[-50:-1] # Remove first 50 values = 0
    Precision_vec = unlist(PR_obj@y.values)[-50:-1] # Remove first 50 values = 0
    ## PRBEP (Precision Recall Break-Even Point)
    Precision_Recall_diff  = abs(Recall_vec-Precision_vec)
    PREBP_index            = which.min(Precision_Recall_diff)[1]
    return_list[["PRBEP"]] = Recall_vec[PREBP_index] #= Precision_vec[PREBP_index]
    ## AUC
    AUC_obj = ROCR::performance(pred,"auc")
    return_list[["AUC"]] = AUC_obj@y.values[[1]]
    ## Lift value as a function of "rate of poisitve predictions"
    LIFT_obj = ROCR::performance(pred, measure="lift", x.measure="rpp")
    return_list[["LIFT"]] = unlist(LIFT_obj@y.values)[1086] # unlist(LIFT_obj@x.values)[[1086]]=0.1
    
    
    options(warn=0)
    return(return_list)
} # end fit_and_evaluate_model
