################################################################################
#                          Precision-Recall Tool                               #
################################################################################
# Probability vector    
y_hat = predictions
# Logical vector (FALSE/TRUE)
y = dataset[test_set_index,"label"] %in% "minority"


PR <- function(y, y_hat)
{
    thresholds = seq(0,1,length.out=1e3)
    alpha.values = tp.values = fp.values = fn_values = tn.values = x.values = y.values = c()
    # Calculate confusion matrices
    for(threshold in thresholds)
    {
        tp = sum(((y_hat>=threshold) & (y==TRUE)))  # true positive
        fp = sum(((y_hat>=threshold) & (y==FALSE))) # false positive
        fn = sum(((y_hat<threshold)  & (y==TRUE)))  # false negative
        tn = sum(((y_hat<threshold)  & (y==FALSE))) # true negative
        
        Recall    = tp/(tp+fn)
        Precision = tp/(tp+fp)
        # if(is.nan(Recall) | is.nan(Precision))
        #     next
        tp.values = c(tp.values,tp)
        fp.values = c(fp.values,fp)
        fn_values = c(fn_values,fn)
        tn.values = c(tn.values,tn)
        x.values  = c(x.values,Recall)
        y.values  = c(y.values,Precision)
        alpha.values = c(alpha.values,threshold)
    }# end confusion matrices
    return(data.frame(alpha.values,tp.values,fp.values,fn_values,tn.values,x.values,y.values))
}# end PR

values = PR(y, y_hat)
# head(values)
tail(values,100)
# ggplot()

