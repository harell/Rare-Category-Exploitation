################################################################################
# Attenberg2013 - 3.1. Support Vector Machines: Distance from the 2D hyper-plane
################################################################################


##################
# Initialization #
##################
rm(list = ls()); cat("\014")
library(e1071) # for svm() 
library(ggplot2) # for visualisation
library(plotly)  # for interactive visualisation


###########################
# Generating the data-set #
###########################
n = 100
Imb.R = 1/10
n_majority = round(n/(1+Imb.R))
n_minority = n-n_majority
set.seed(2016)
x_majority = MASS::mvrnorm(n_majority, mu=rep(-1,2), Sigma=diag(rep(1,2)))
x_minority = MASS::mvrnorm(n_minority, mu=rep(+1,2), Sigma=diag(rep(1,2)))

x     = rbind(x_majority, x_minority)
label = factor(c(rep("majority",n_majority),rep("minority",n_minority)))
A     = data.frame(x,label)

# fig_total     <- ggplot(A, aes(x=X1)) + geom_density()
fig_separated_1 <- ggplot(A, aes(x=X1, col=label)) + geom_density(aes(group=label))
fig_separated_2 <- ggplot(A, aes(x=X2, col=label)) + geom_density(aes(group=label))


##########################
# Splitting the data-set #
##########################
#' 70%/30% split
index_train = sample(n,round(0.7*n))
A_tr = A[+index_train,]
A_te = A[-index_train,]


#########################################
# Fitting SVM model on the training-set #
#########################################
svm_model <- e1071::svm(label~X1+X2, data=A_tr, 
                        type='C-classification', kernel='linear',
                        scale=FALSE, probability=TRUE)


###########################
# Predicting the test-set #
###########################
y_hat = predict(svm_model, A_te, probability=TRUE)
y_hat = attr(y_hat, "probabilities")
A_te$class = ifelse(as.numeric(A_te$label)==1,-1,1)
A_te$minority_probability = as.vector(y_hat[,"minority"]) 
#A_te$hyperplane_distance = 


####################
# Evaluating model #
####################
pred    = ROCR::prediction(A_te$minority_probability, A_te$label)
AUC_obj = ROCR::performance(pred,"auc")
AUC_obj@y.values[[1]]


#################
# Visualisation #
#################
hist(A_te$minority_probability, 30)
fig1 <- ggplot(A_te, aes(X1, X2)) + ggtitle("Visualisation of the test-set") + 
    geom_point(aes(colour = minority_probability,shape=label)) + 
    scale_colour_gradient(low = "red", high = "green")
plot(fig1)


#######################
# Choosing the cutoff #
#######################
prob_quantile = round(quantile(A_te$minority_probability,c(0.99)),3)
cat("\n",rep("#",40),
    "\n", "# Test-set probability statistics:",
    "\n", "# mean = ", round(mean(A_te$minority_probability),3),
    "\n", "# median = ", round(median(A_te$minority_probability),3),
    "\n", "# 99% quantile = ",prob_quantile,
    sep="")


##################################
# Reconstructing the hyper-plane #
##################################
# Get parameters of hiperplane
w  = t(svm_model$coefs) %*% svm_model$SV
w1 = w[,1]; w2 = w[,2]
b  = svm_model$rho
w;b
b/sqrt(sum(w^2))


# b - w1 * A_te$X1 - w2 * A_te$X2



fig1 <- fig1 + geom_abline(intercept=b, slope=-w1/w2)
ggplotly(fig1)


# Get the support vectors
SV = A_tr[svm_model$index,]
table(SV$label); prop.table(table(SV$label))