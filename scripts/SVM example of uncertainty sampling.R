################################################################################
#  Example of uncertainty sampling with SVM 
################################################################################


##################
# Initialization #
##################
rm(list = ls()); cat("\014")
source("scripts/load_libraries.R")
invisible(sapply(list.files(pattern="[.]R$", path="./functions/", full.names=TRUE), source))
options(digits=3)


################
# Toy data set #
################
n = 500
r = 10
n_minority = round(n/(r+1))
n_majority = n - n_minority
n_tr = 100
cat("\n Imbalanced ratio =",round(n_majority/n_minority,1))
q = 30 # number of query points
set.seed(1301)
X_majority = MASS::mvrnorm(n=n, mu=c(-2,0), Sigma=diag(1,2))
X_minority = MASS::mvrnorm(n=n, mu=c(+2,0), Sigma=diag(1,2))
X = rbind(X_majority[1:n_majority,],X_minority[1:n_minority,])
y = factor(c(rep("majority",n_majority),rep("minority",n_minority)))
dataset = data.frame(X=X,y=y)
# Plots attributes
dataset$pch = ifelse(dataset$y=="majority",45,43) # in ggplot2 45="-",43="+"
dataset$col = ifelse(dataset$y=="majority","springgreen4","red")


############################################
# Train SVM with randomly chosen instances #
############################################
# Select q labeled instances randomly for training set
set.seed(1044)
random_index = sample(1:nrow(X),n_tr)
dataset$type = factor(ifelse(1:nrow(dataset) %in% random_index, "labeled", "unlabeled"))
dataset[random_index,"type"] = "labeled"
table(dataset[random_index,"y"])
table(dataset[-random_index,"y"])
# Fit SVM model
mdl.SVM = e1071::svm(y ~ ., data=dataset[random_index,c("X.1","X.2","y")],
                     kernel="linear", type="C-classification",
                     cost=1e0, scale=T, probability=TRUE)
# Store information about the support vectors
## Flag the support vectors
dataset$SV = factor(ifelse((1:nrow(dataset)) %in% random_index[mdl.SVM$index],"Yes","No"))


##################################
# Reconstructing the hyper-plane #
##################################
# See more information at:
# <https://cran.r-project.org/web/packages/e1071/vignettes/svminternals.pdf>
## Get the parameters of hiperplane
w  = t(mdl.SVM$coefs) %*% mdl.SVM$SV
w0 = mdl.SVM$rho
w1 = w[1,1]
w2 = w[1,2]


#########################
# Choose the next batch #
#########################
# Query by Random
set.seed(1803)
random_policy = sample((1:nrow(dataset))[-random_index],q)
dataset$inc_random_policy = (1:nrow(dataset)) %in% random_policy
# Query by uncertainty sampling
# n=-b, m=-w1/w2
est_tr = predict(mdl.SVM, dataset[,c("X.1","X.2")], probability=TRUE)
est_tr = attr(est_tr, "probabilities")
predictions_tr = unlist(est_tr[,"minority"])
us_policy = head(sort(abs(0.5-predictions_tr[-random_index])),q)
us_policy = as.numeric(names(us_policy))
dataset$inc_us_policy = (1:nrow(dataset)) %in% us_policy


##################
# Visualisations #
##################
par(mfrow=c(1,3))
# Plot (a) - A toy data set of 400 instances, evenly sampled from two class
# Gaussians.
plot(dataset[,1], dataset[,2],
     col=dataset$col,pch=dataset$pch, cex=2,
     xlim=c(-5,+5), ylim=c(-3,+3),
     sub="(a)", xlab="", ylab="")
# abline(a=w0/w2,      b=-w1/w2, col="blue", lwd=2)
# abline(a=(1+w0)/w2,  b=-w1/w2, col="blue", lwd=2, lty=2)
# abline(a=(-1+w0)/w2, b=-w1/w2, col="blue", lwd=2, lty=2)
# points(dataset[dataset$SV %in% "Yes",c("X.1","X.2")], pch="o", cex=2) # SV


# Plot (b) - SVM model trained with 100 labeled instances randomly drawn from
# the problem domain with then next batch chosen according to random policy.
plot(dataset[-random_index,1], dataset[-random_index,2],
     col="snow3", pch=".", cex=3,
     xlim=c(-5,+5), ylim=c(-3,+3),
     sub="(b)", xlab="", ylab="")
points(x=dataset[random_policy,1],
       y=dataset[random_policy,2],
       col=dataset[random_policy,"col"], pch=dataset[random_policy,"pch"], cex=2)
# points(dataset[dataset$SV %in% "Yes",c("X.1","X.2")], pch="o", cex=2) # SV
abline(a=w0/w2,      b=-w1/w2, col="blue", lwd=2)
abline(a=(1+w0)/w2,  b=-w1/w2, col="blue", lwd=2, lty=2)
abline(a=(-1+w0)/w2, b=-w1/w2, col="blue", lwd=2, lty=2)
s1 = sum(dataset[random_policy,"y"] %in% "minority")
text(-5,-3,paste(s1,"out of",q,"are minority cases"),pos=4)

# Plot (c) - SVM model trained with 100 labeled instances randomly drawn from
# the problem domain with then next batch chosen according to uncertainty sampling.
plot(dataset[-random_index,1], dataset[-random_index,2],
     col="snow3", pch=".", cex=3,
     xlim=c(-5,+5), ylim=c(-3,+3),
     sub="(c)", xlab="", ylab="")
points(x=dataset[us_policy,1],
       y=dataset[us_policy,2],
       col=dataset[us_policy,"col"], pch=dataset[us_policy,"pch"], cex=2)
# points(dataset[dataset$SV %in% "Yes",c("X.1","X.2")], pch="o", cex=2) # SV
abline(a=w0/w2,      b=-w1/w2, col="blue", lwd=2)
abline(a=(1+w0)/w2,  b=-w1/w2, col="blue", lwd=2, lty=2)
abline(a=(-1+w0)/w2, b=-w1/w2, col="blue", lwd=2, lty=2)
s2 = sum(dataset[us_policy,"y"] %in% "minority")
text(-5,-3,paste(s2,"out of",q,"are minority cases"),pos=4)