################################################################################
#  Example of uncertainty sampling with SVM 
################################################################################


##################
# Initialization #
##################
rm(list = ls()); cat("\014")
source("scripts/load_libraries.R")
invisible(sapply(list.files(pattern="[.]R$", path="./functions/", full.names=TRUE), source))
options(digits=3)


################
# Toy data set #
################
n = 500
r = 10
n_minority = round(n/(r+1))
n_majority = n - n_minority
cat("\n Imbalanced ratio =",round(n_majority/n_minority,1))
q = 100 # number of query points
set.seed(1544)
X_majority = MASS::mvrnorm(n=n, mu=c(-2,0), Sigma=diag(1,2))
X_minority = MASS::mvrnorm(n=n, mu=c(+2,0), Sigma=diag(1,2))
X = rbind(X_majority[1:n_majority,],X_minority[1:n_minority,])
y = factor(c(rep("majority",n_majority),rep("minority",n_minority)))
dataset = data.frame(X=X,y=y)
# Plots attributes
dataset$pch = ifelse(dataset$y=="majority","-","+")
dataset$col = ifelse(dataset$y=="majority","springgreen4","red")


############################################
# Train SVM with randomly chosen instances #
############################################
# Select q labeled instances randomly
random_index = sample(1:nrow(X),q)
dataset$type = "unlabeled"
dataset[random_index,"type"] = "labeled"
table(dataset[random_index,"y"])

# Fit SVM model
mdl.SVM = e1071::svm(y ~ ., data=dataset[,1:3], subset=random_index,
                     kernel="linear", cost=1e0,
                     scale=T, probability=TRUE)


##################################
# Reconstructing the hyper-plane #
##################################
SV_info = data.frame()
# Get parameters of hiperplane
w  = t(mdl.SVM$coefs) %*% mdl.SVM$SV
w1 = w[,1]; w2 = w[,2]
b  = mdl.SVM$rho
# Flag the support vectors
dataset[,"SV"]              = "No"
dataset[mdl.SVM$index,"SV"] = "Yes"
dataset$SV                  = factor(dataset$SV)


#########################
# Choose the next batch #
#########################
# Query by Random
set.seed(1733)
random_policy = sample((1:nrow(dataset))[-random_index],q)
# Query by uncertainty sampling
# n=-b, m=-w1/w2
est_tr = predict(mdl.SVM, dataset[,1:2], probability=TRUE)
est_tr = attr(est_tr, "probabilities")
predictions_tr = unlist(est_tr[,"minority"])
us_policy = head(sort(abs(0.5-predictions_tr[-random_index])),q)
us_policy = as.numeric(names(us_policy))


##################
# Visualisations #
##################
par(mfrow=c(1,3))

# Plot (a) - A toy data set of 400 instances, evenly sampled from two class
# Gaussians.
plot(dataset[,1], dataset[,2], 
     col=dataset$col,pch=dataset$pch, cex=2, 
     xlim=c(-5,+5), ylim=c(-3,+3),
     sub="(a)", xlab="", ylab="")


# Plot (b) - SVM model trained with 100 labeled instances randomly drawn from 
# the problem domain with then next batch chosen according to random policy.
plot(dataset[-random_index,1], dataset[-random_index,2], 
     col="snow3", pch=".", cex=3, 
     xlim=c(-5,+5), ylim=c(-3,+3),
     sub="(b)", xlab="", ylab="")
points(x=dataset[random_policy,1], 
       y=dataset[random_policy,2],
       col=dataset[random_policy,"col"], pch=dataset[random_policy,"pch"], cex=2)
abline(a=-b, b=-w1/w2, col="blue", lwd=2)
s1 = sum(dataset[random_policy,"y"] %in% "minority")
text(-5,-3,paste(s1,"out of",q,"are minority cases"),pos=4)


# Plot (c) - SVM model trained with 100 labeled instances randomly drawn from 
# the problem domain with then next batch chosen according to uncertainty sampling.
plot(dataset[-random_index,1], dataset[-random_index,2], 
     col="snow3", pch=".", cex=3, 
     xlim=c(-5,+5), ylim=c(-3,+3),
     sub="(c)", xlab="", ylab="")
points(x=dataset[us_policy,1], 
       y=dataset[us_policy,2],
       col=dataset[us_policy,"col"], pch=dataset[us_policy,"pch"], cex=2)
abline(a=-b, b=-w1/w2, col="blue", lwd=2)
s2 = sum(dataset[us_policy,"y"] %in% "minority")
text(-5,-3,paste(s2,"out of",q,"are minority cases"),pos=4)